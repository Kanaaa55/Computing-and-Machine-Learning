{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c998a6a0-2380-4929-9bfc-94a2eb57916f",
   "metadata": {},
   "source": [
    "---\n",
    "self-contained: true\n",
    "title: \"Lab 6: Variable Selection and Regularization\"\n",
    "author: \"Ruojia Kuang\"\n",
    "format:\n",
    "  html: \n",
    "    theme: cosmo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d48d51f4-a059-46f0-a799-72b41532ed1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "048087f0-754d-4e98-aac9-f5d2f2eb27d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "hitters = pd.read_csv(\"/Users/ruojiakuang/Desktop/GSB S544 Computing and Machine Learning for Business Analytics/dataset/Hitters.csv\")\n",
    "\n",
    "# Get rid of columns with mostly NaN values\n",
    "good_cols = hitters.isna().sum() < 100\n",
    "hitters = hitters.loc[:,good_cols]\n",
    "\n",
    "# Drop other NAs\n",
    "hitters = hitters.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44bd8870-a987-41d0-81f9-0b1e5af62b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "1    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "2    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "4    321    87     10    39   42     30      2     396    101      12     48   \n",
       "5    594   169      4    74   51     35     11    4408   1133      19    501   \n",
       "\n",
       "   CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary NewLeague  \n",
       "1   414     375      N        W      632       43      10   475.0         N  \n",
       "2   266     263      A        W      880       82      14   480.0         A  \n",
       "3   838     354      N        E      200       11       3   500.0         N  \n",
       "4    46      33      N        E      805       40       4    91.5         N  \n",
       "5   336     194      A        W      282      421      25   750.0         A  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4887a9ae-27d4-48cf-9e6d-e1a10bdded81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = hitters.drop([\"Salary\"], axis = 1)\n",
    "y = hitters[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789ffa6-71e4-485c-adb8-319b9ceac5dd",
   "metadata": {},
   "source": [
    "# Part1 A. Regression without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebd18c4d-2593-4360-bd62-b0e21f3a2040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;dummify&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x143130dd0&gt;),\n",
       "                                                 (&#x27;standardize&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x145102e10&gt;)])),\n",
       "                (&#x27;linear_regression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;dummify&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x143130dd0&gt;),\n",
       "                                                 (&#x27;standardize&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x145102e10&gt;)])),\n",
       "                (&#x27;linear_regression&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;dummify&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x143130dd0&gt;),\n",
       "                                (&#x27;standardize&#x27;, StandardScaler(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x145102e10&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">dummify</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x143130dd0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standardize</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x145102e10&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('dummify',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse_output=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x143130dd0>),\n",
       "                                                 ('standardize',\n",
       "                                                  StandardScaler(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x145102e10>)])),\n",
       "                ('linear_regression', LinearRegression())])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ")\n",
    "\n",
    "lr_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d876e39-134a-48f4-943d-fe353b8b7df1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -31.29971152,   31.29971152,   58.42462282,  -58.42462282,\n",
       "         12.38116255,  -12.38116255, -291.0945557 ,  337.83047948,\n",
       "         37.85383676,  -60.57247861,  -26.99498379,  135.07389695,\n",
       "        -16.69335888, -391.03865466,   86.68761664,  -14.18172332,\n",
       "        480.74713477,  260.68988581, -213.89225864,   78.76129639,\n",
       "         53.73248973,  -22.16086217])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline_fitted = lr_pipeline.fit(X, y)\n",
    "lr_pipeline_fitted.named_steps['linear_regression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee6b535a-a69e-4e81-bcd8-8cd54c281d47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'CRuns': 480.747134770793,\n",
       "  'CAtBat': -391.03865466353824,\n",
       "  'Hits': 337.8304794814835,\n",
       "  'AtBat': -291.09455569714925,\n",
       "  'CRBI': 260.68988580523126,\n",
       "  'CWalks': -213.8922586429127,\n",
       "  'Walks': 135.07389695131255,\n",
       "  'CHits': 86.68761663772091,\n",
       "  'PutOuts': 78.76129639492675,\n",
       "  'Runs': -60.5724786055111,\n",
       "  'Division_W': -58.42462281843828,\n",
       "  'Division_E': 58.42462281843723,\n",
       "  'Assists': 53.73248973474432,\n",
       "  'HmRun': 37.85383676434323,\n",
       "  'League_N': 31.299711517594083,\n",
       "  'League_A': -31.299711517594076,\n",
       "  'RBI': -26.99498378992112,\n",
       "  'Errors': -22.16086217422561,\n",
       "  'Years': -16.69335887510299,\n",
       "  'CHmRun': -14.18172332300868,\n",
       "  'NewLeague_N': -12.381162554200458,\n",
       "  'NewLeague_A': 12.381162554199951},\n",
       " 121136.3103181688)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with missing 'Salary' values\n",
    "hitters_cleaned = hitters.dropna(subset=['Salary'])\n",
    "\n",
    "# Define predictors and target\n",
    "X = hitters_cleaned.drop('Salary', axis=1)\n",
    "y = hitters_cleaned['Salary']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Create a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline with preprocessing and linear regression model\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline.fit(X, y)\n",
    "\n",
    "# Extract coefficients from the linear regression model\n",
    "model_coefficients = lr_pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Map coefficients to their corresponding feature names\n",
    "feature_names = np.concatenate([numerical_cols, preprocessor.named_transformers_['cat'].get_feature_names_out()])\n",
    "coefficients = dict(zip(feature_names, model_coefficients))\n",
    "\n",
    "# Sort coefficients by absolute value\n",
    "sorted_coefficients = dict(sorted(coefficients.items(), key=lambda item: abs(item[1]), reverse=True))\n",
    "\n",
    "# Perform cross-validation to estimate MSE\n",
    "mse_scores = -cross_val_score(lr_pipeline, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mean_mse = np.mean(mse_scores)\n",
    "\n",
    "sorted_coefficients, mean_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ef3e2-e6de-4647-a38d-f2eaf926656e",
   "metadata": {},
   "source": [
    "The coefficient of Cruns is 480.75, suggesting that career runs scored has a significant positive impact on salary. The coefficient of CAtBat is -391.04 indicating that one unit increse in number of time at bat will cause a negative 391.04 units impact on salary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e1d22e-2b90-4932-997d-286c5c73f44a",
   "metadata": {},
   "source": [
    "The estimated Mean Squared Error (MSE) from cross-validation is approximately 121,136.31. This value represents the average squared difference between the actual and predicted salaries. A lower MSE indicates a more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821c653-0d68-4e04-996b-1399663a7aab",
   "metadata": {},
   "source": [
    "# B. Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c708864-5474-439a-850d-be66fe1b293c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;num&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         Index([&#x27;AtBat&#x27;, &#x27;Hits&#x27;, &#x27;HmRun&#x27;, &#x27;Runs&#x27;, &#x27;RBI&#x27;, &#x27;Walks&#x27;, &#x27;Years&#x27;, &#x27;CAtBat&#x27;,\n",
       "       &#x27;CHits&#x27;, &#x27;CHmRun&#x27;, &#x27;CRuns&#x27;, &#x27;CRBI&#x27;, &#x27;CWalks&#x27;, &#x27;PutOuts&#x27;, &#x27;Assists&#x27;,\n",
       "       &#x27;Errors&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                                        (&#x27;cat&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         Index([&#x27;League&#x27;, &#x27;Division&#x27;, &#x27;NewLeague&#x27;], dtype=&#x27;object&#x27;))])),\n",
       "                                       (&#x27;regressor&#x27;, Ridge())]),\n",
       "             param_grid={&#x27;regressor__alpha&#x27;: [0.1, 1, 10, 100, 1000]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;num&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         Index([&#x27;AtBat&#x27;, &#x27;Hits&#x27;, &#x27;HmRun&#x27;, &#x27;Runs&#x27;, &#x27;RBI&#x27;, &#x27;Walks&#x27;, &#x27;Years&#x27;, &#x27;CAtBat&#x27;,\n",
       "       &#x27;CHits&#x27;, &#x27;CHmRun&#x27;, &#x27;CRuns&#x27;, &#x27;CRBI&#x27;, &#x27;CWalks&#x27;, &#x27;PutOuts&#x27;, &#x27;Assists&#x27;,\n",
       "       &#x27;Errors&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                                        (&#x27;cat&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         Index([&#x27;League&#x27;, &#x27;Division&#x27;, &#x27;NewLeague&#x27;], dtype=&#x27;object&#x27;))])),\n",
       "                                       (&#x27;regressor&#x27;, Ridge())]),\n",
       "             param_grid={&#x27;regressor__alpha&#x27;: [0.1, 1, 10, 100, 1000]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  Index([&#x27;AtBat&#x27;, &#x27;Hits&#x27;, &#x27;HmRun&#x27;, &#x27;Runs&#x27;, &#x27;RBI&#x27;, &#x27;Walks&#x27;, &#x27;Years&#x27;, &#x27;CAtBat&#x27;,\n",
       "       &#x27;CHits&#x27;, &#x27;CHmRun&#x27;, &#x27;CRuns&#x27;, &#x27;CRBI&#x27;, &#x27;CWalks&#x27;, &#x27;PutOuts&#x27;, &#x27;Assists&#x27;,\n",
       "       &#x27;Errors&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  Index([&#x27;League&#x27;, &#x27;Division&#x27;, &#x27;NewLeague&#x27;], dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;regressor&#x27;, Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;AtBat&#x27;, &#x27;Hits&#x27;, &#x27;HmRun&#x27;, &#x27;Runs&#x27;, &#x27;RBI&#x27;, &#x27;Walks&#x27;, &#x27;Years&#x27;, &#x27;CAtBat&#x27;,\n",
       "       &#x27;CHits&#x27;, &#x27;CHmRun&#x27;, &#x27;CRuns&#x27;, &#x27;CRBI&#x27;, &#x27;CWalks&#x27;, &#x27;PutOuts&#x27;, &#x27;Assists&#x27;,\n",
       "       &#x27;Errors&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                 Index([&#x27;League&#x27;, &#x27;Division&#x27;, &#x27;NewLeague&#x27;], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;AtBat&#x27;, &#x27;Hits&#x27;, &#x27;HmRun&#x27;, &#x27;Runs&#x27;, &#x27;RBI&#x27;, &#x27;Walks&#x27;, &#x27;Years&#x27;, &#x27;CAtBat&#x27;,\n",
       "       &#x27;CHits&#x27;, &#x27;CHmRun&#x27;, &#x27;CRuns&#x27;, &#x27;CRBI&#x27;, &#x27;CWalks&#x27;, &#x27;PutOuts&#x27;, &#x27;Assists&#x27;,\n",
       "       &#x27;Errors&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;League&#x27;, &#x27;Division&#x27;, &#x27;NewLeague&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         Index(['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years', 'CAtBat',\n",
       "       'CHits', 'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'PutOuts', 'Assists',\n",
       "       'Errors'],\n",
       "      dtype='object')),\n",
       "                                                                        ('cat',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         Index(['League', 'Division', 'NewLeague'], dtype='object'))])),\n",
       "                                       ('regressor', Ridge())]),\n",
       "             param_grid={'regressor__alpha': [0.1, 1, 10, 100, 1000]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Creating the ridge regression model\n",
    "ridge_reg = Ridge()\n",
    "\n",
    "# Creating a pipeline that first preprocesses the data and then applies ridge regression\n",
    "ridge_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', ridge_reg)])\n",
    "\n",
    "# Parameters for GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 1, 10, 100, 1000]  # Different values for lambda (alpha in Ridge)\n",
    "}\n",
    "\n",
    "# Setting up the GridSearchCV to tune hyperparameters\n",
    "grid_search = GridSearchCV(ridge_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59574cf2-a543-4b67-98a6-2d814449b655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 119144.43267691582,\n",
       " CRuns     320.412169\n",
       " Hits      296.645050\n",
       " AtBat     270.686441\n",
       " CAtBat    225.406548\n",
       " CWalks    184.423611\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the best hyperparameter (lambda) and corresponding mean cross-validated MSE\n",
    "best_lambda = grid_search.best_params_['regressor__alpha']\n",
    "best_mse = -grid_search.best_score_\n",
    "\n",
    "# Fitting the pipeline on the full dataset with the chosen lambda\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Getting the coefficients from the ridge regression model\n",
    "ridge_coef = best_model.named_steps['regressor'].coef_\n",
    "\n",
    "# Since we have one-hot encoded some variables, we need to adjust the feature names\n",
    "# Get feature names after preprocessing\n",
    "ohe_categories = best_model.named_steps['preprocessor'].named_transformers_['cat'].categories_\n",
    "new_categorical_features = [f'{col}_{cat}' for col, cats in zip(categorical_cols, ohe_categories) for cat in cats]\n",
    "all_features = np.concatenate([numerical_cols, new_categorical_features])\n",
    "\n",
    "# Pairing coefficients with their corresponding feature names\n",
    "feature_coef = pd.Series(ridge_coef, index=all_features)\n",
    "\n",
    "# Sorting the coefficients by their absolute values to find the most influential ones\n",
    "sorted_coef = feature_coef.abs().sort_values(ascending=False)\n",
    "\n",
    "best_lambda, best_mse, sorted_coef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2827993-5e0e-4ed5-bdd5-2875c3b5ad30",
   "metadata": {},
   "source": [
    "The MSE you would expect is 119144.43 if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfa284-f7b2-4630-9674-eaa03c9987be",
   "metadata": {},
   "source": [
    "# C. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d65bb45f-39c4-4f36-9f59-a51c15aba1d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the Lasso regression model\n",
    "lasso_reg = Lasso(max_iter=10000)  # Increasing max_iter for convergence\n",
    "\n",
    "# Creating a pipeline that first preprocesses the data and then applies Lasso regression\n",
    "lasso_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', lasso_reg)])\n",
    "\n",
    "# Parameters for GridSearchCV for Lasso\n",
    "lasso_param_grid = {\n",
    "    'regressor__alpha': [0.001, 0.01, 0.1, 1, 10]  # Different values for lambda in Lasso\n",
    "}\n",
    "\n",
    "# Setting up the GridSearchCV for Lasso\n",
    "lasso_grid_search = GridSearchCV(lasso_pipeline, lasso_param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "# Fit the grid search to the data for Lasso\n",
    "lasso_pipeline_fitted = lasso_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b7e5131-49c3-4bbe-8026-037c6730584d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 119758.2278152887,\n",
       " CRuns     375.565034\n",
       " Hits      304.358267\n",
       " AtBat     282.369623\n",
       " CRBI      192.616442\n",
       " CWalks    189.643123\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the best hyperparameter (lambda) and corresponding mean cross-validated MSE\n",
    "best_lambda = lasso_grid_search.best_params_['regressor__alpha']\n",
    "best_mse = -lasso_grid_search.best_score_\n",
    "\n",
    "# Fitting the pipeline on the full dataset with the chosen lambda\n",
    "best_model = lasso_grid_search.best_estimator_\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Getting the coefficients from the lasso regression model\n",
    "lasso_coef = best_model.named_steps['regressor'].coef_\n",
    "\n",
    "# Since we have one-hot encoded some variables, we need to adjust the feature names\n",
    "# Get feature names after preprocessing\n",
    "ohe_categories = best_model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out()\n",
    "all_features = np.concatenate([numerical_cols, ohe_categories])\n",
    "\n",
    "# Pairing coefficients with their corresponding feature names\n",
    "feature_coef = pd.Series(lasso_coef, index=all_features)\n",
    "\n",
    "# Sorting the coefficients by their absolute values to find the most influential ones\n",
    "sorted_coef = feature_coef.abs().sort_values(ascending=False)\n",
    "\n",
    "best_lambda, best_mse, sorted_coef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033c0a0-6b59-4329-846c-92324221c984",
   "metadata": {},
   "source": [
    "The MSE you would expect is 119758.23 if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd78f71-b147-417d-ace7-1f11427e8acc",
   "metadata": {},
   "source": [
    "# D. Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "832302f5-2b92-44e5-b5a3-e83bbbbe9fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.639e+05, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.977e+05, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.665e+06, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+05, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.744e+05, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.9}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a pipeline with ElasticNet and the preprocessor\n",
    "elastic_net_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', ElasticNet())\n",
    "])\n",
    "\n",
    "# Parameters for grid search\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    'regressor__l1_ratio': [0.1, 0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "elastic_net_grid_search = GridSearchCV(elastic_net_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fitting the grid search\n",
    "elastic_net_grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters\n",
    "best_params = elastic_net_grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c5131d5-7ffb-4301-ba5f-ffb27e441745",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 118969.49145597247,\n",
       " Hits      247.556168\n",
       " AtBat     231.507759\n",
       " CRuns     223.037799\n",
       " CWalks    154.668795\n",
       " CRBI      121.693876\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mse = -elastic_net_grid_search.best_score_\n",
    "# Updating the pipeline with the best parameters\n",
    "elastic_net_pipeline.set_params(**{'regressor__alpha': best_params['regressor__alpha'], \n",
    "                                   'regressor__l1_ratio': best_params['regressor__l1_ratio']})\n",
    "\n",
    "# Fitting the model to the full dataset\n",
    "best_model = elastic_net_pipeline.fit(X, y)\n",
    "\n",
    "# Getting the coefficients from the ridge regression model\n",
    "elastic_net_coef = best_model.named_steps['regressor'].coef_\n",
    "\n",
    "# Since we have one-hot encoded some variables, we need to adjust the feature names\n",
    "# Get feature names after preprocessing\n",
    "ohe_categories = best_model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out()\n",
    "all_features = np.concatenate([numerical_cols, ohe_categories])\n",
    "\n",
    "# Pairing coefficients with their corresponding feature names\n",
    "feature_coef = pd.Series(elastic_net_coef, index=all_features)\n",
    "\n",
    "# Sorting the coefficients by their absolute values to find the most influential ones\n",
    "sorted_coef = feature_coef.abs().sort_values(ascending=False)\n",
    "\n",
    "best_lambda, best_mse, sorted_coef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e7e9d-5c0c-487f-acfc-728be6cc9305",
   "metadata": {},
   "source": [
    "The MSE you would expect is 118969.49 if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf757b9d-04cb-4e85-95fb-ca3d6d5e3014",
   "metadata": {},
   "source": [
    "# Part II. Variable Selection\n",
    "Based on the above results, decide on:\n",
    "\n",
    "1. Which numeric variable is most important.\n",
    "    CRuns\n",
    "\n",
    "2. Which five numeric variables are most important\n",
    "    CRuns, AtBat, Hits, CWalks, CRBI\n",
    "\n",
    "3. Which categorical variable is most important\n",
    "    Division\n",
    "\n",
    "For each of the four model specifications, compare the following possible feature sets:\n",
    "\n",
    "1. Using only the one best numeric variable.\n",
    "\n",
    "2. Using only the five best variables.\n",
    "\n",
    "3. Using the five best numeric variables and their interactions with the one best categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0562351e-3546-40e6-8d9a-98ec76c55935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 19), (53, 19), (210,), (53,))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = hitters_cleaned.drop('Salary', axis=1)\n",
    "y = hitters_cleaned['Salary']\n",
    "\n",
    "# Identifying numeric and categorical columns for preprocessing\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Creating column transformers for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['CRuns'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the shape of the train and test sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "97430780-ba45-417b-ab04-c5e76de1bfb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Linear Regression': 146326.05786366438,\n",
       "  'Ridge Regression': 145749.92477733022,\n",
       "  'Lasso Regression': 145483.75775418183,\n",
       "  'Elastic Net Regression': 145437.0797263119},\n",
       " {'Linear Regression': 146326.05786366438,\n",
       "  'Ridge Regression': 145749.92477733022,\n",
       "  'Lasso Regression': 145483.75775418183,\n",
       "  'Elastic Net Regression': 145437.0797263119})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "\n",
    "# Creating pipelines for each regression model\n",
    "linear_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())])\n",
    "ridge_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', RidgeCV())])\n",
    "lasso_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LassoCV(random_state=42))])\n",
    "elastic_net_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', ElasticNetCV(random_state=42))])\n",
    "\n",
    "# List of pipelines for easy iteration\n",
    "pipelines = [\n",
    "    ('Linear Regression', linear_pipeline),\n",
    "    ('Ridge Regression', ridge_pipeline),\n",
    "    ('Lasso Regression', lasso_pipeline),\n",
    "    ('Elastic Net Regression', elastic_net_pipeline)\n",
    "]\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_evaluate_model(pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "# Evaluating each model using the full set of features\n",
    "full_feature_results = {}\n",
    "for name, pipeline in pipelines:\n",
    "    mse = train_evaluate_model(pipeline, X_train, y_train, X_test, y_test)\n",
    "    full_feature_results[name] = mse\n",
    "\n",
    "# Evaluating each model using only the \"CRuns\" variable\n",
    "X_train_cruns = X_train[['CRuns']]\n",
    "X_test_cruns = X_test[['CRuns']]\n",
    "cruns_feature_results = {}\n",
    "for name, pipeline in pipelines:\n",
    "    mse = train_evaluate_model(pipeline, X_train_cruns, y_train, X_test_cruns, y_test)\n",
    "    cruns_feature_results[name] = mse\n",
    "\n",
    "full_feature_results, cruns_feature_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23d35715-55cf-4b95-992c-5883b1f20dce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': 157060.03051511134,\n",
       " 'Ridge Regression': 157932.08365510276,\n",
       " 'Lasso Regression': 157120.827555729,\n",
       " 'Elastic Net Regression': 156981.28375384555}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using only the five best variables \"CRuns, AtBat, Hits, CWalks, CRBI\"\n",
    "# Selected variables\n",
    "selected_features = ['CRuns', 'AtBat', 'Hits', 'CWalks', 'CRBI']\n",
    "\n",
    "# Preprocessor for the selected variables\n",
    "preprocessor_selected = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), selected_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creating pipelines for each regression model using the selected variables preprocessor\n",
    "linear_pipeline_selected = Pipeline(steps=[('preprocessor', preprocessor_selected), ('regressor', LinearRegression())])\n",
    "ridge_pipeline_selected = Pipeline(steps=[('preprocessor', preprocessor_selected), ('regressor', RidgeCV())])\n",
    "lasso_pipeline_selected = Pipeline(steps=[('preprocessor', preprocessor_selected), ('regressor', LassoCV(random_state=42))])\n",
    "elastic_net_pipeline_selected = Pipeline(steps=[('preprocessor', preprocessor_selected), ('regressor', ElasticNetCV(random_state=42))])\n",
    "\n",
    "# List of pipelines for using the selected variables\n",
    "pipelines_selected = [\n",
    "    ('Linear Regression', linear_pipeline_selected),\n",
    "    ('Ridge Regression', ridge_pipeline_selected),\n",
    "    ('Lasso Regression', lasso_pipeline_selected),\n",
    "    ('Elastic Net Regression', elastic_net_pipeline_selected)\n",
    "]\n",
    "\n",
    "# Extracting the training and testing data for the selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Evaluating each model using the selected variables\n",
    "selected_feature_results = {}\n",
    "for name, pipeline in pipelines_selected:\n",
    "    mse = train_evaluate_model(pipeline, X_train_selected, y_train, X_test_selected, y_test)\n",
    "    selected_feature_results[name] = mse\n",
    "\n",
    "selected_feature_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b7b02a5-472f-472d-b59b-8228233750bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3677.517927888781, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4958.7609727252275, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5093.6246394477785, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5081.0271981321275, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5027.566752705723, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4948.919436799362, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4851.23857653141, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4739.042677713558, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4616.064267419279, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4485.419970210642, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4341.049651324749, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5298.167562663555, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6172.538086313754, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6115.212092004716, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5974.1471057180315, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5825.031176943332, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5670.949871486053, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5513.868288952857, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5355.706511441618, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5198.056987382472, tolerance: 3170.8085667635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3462.2703094668686, tolerance: 3373.2933883627284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4302.464898064733, tolerance: 3373.2933883627284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4127.08653915301, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4395.822964429855, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4390.742344344035, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4341.649900896475, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4271.092925950885, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4184.798051929101, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4086.5751320626587, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3979.545293821022, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3866.3119057007134, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3749.0406784303486, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3629.5237002559006, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3509.2343051433563, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7418.224747726694, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7948.272292790934, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7842.120526071638, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7671.020204931498, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7491.301111156121, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7310.043491097167, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7129.480695579201, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6951.098447116092, tolerance: 3424.5359560019288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5698.753213882446, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6748.545501515269, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6717.448694596067, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6582.2898673936725, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6428.687763342634, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6266.608420036733, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6099.480571795255, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5929.756713775918, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5759.4195754006505, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/ruojiakuang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5590.080485332757, tolerance: 3897.8748046168844\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': 133346.2466579313,\n",
       " 'Ridge Regression': 120342.51619954883,\n",
       " 'Lasso Regression': 129143.16331437798,\n",
       " 'Elastic Net Regression': 113926.2249774629}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Selected numeric and categorical variables\n",
    "numeric_features = ['CRuns', 'AtBat', 'Hits', 'CWalks', 'CRBI']\n",
    "categorical_features = ['Division']\n",
    "\n",
    "# Preprocessors for numeric and categorical features\n",
    "numeric_preprocessor = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Combined preprocessor using FeatureUnion\n",
    "combined_preprocessor = FeatureUnion(transformer_list=[\n",
    "    ('num', ColumnTransformer(transformers=[('num', numeric_preprocessor, numeric_features)])),\n",
    "    ('cat', ColumnTransformer(transformers=[('cat', categorical_preprocessor, categorical_features)]))\n",
    "])\n",
    "\n",
    "# Creating pipelines for each regression model using the combined preprocessor\n",
    "linear_pipeline_interaction = Pipeline(steps=[('preprocessor', combined_preprocessor), ('regressor', LinearRegression())])\n",
    "ridge_pipeline_interaction = Pipeline(steps=[('preprocessor', combined_preprocessor), ('regressor', RidgeCV())])\n",
    "lasso_pipeline_interaction = Pipeline(steps=[('preprocessor', combined_preprocessor), ('regressor', LassoCV(random_state=42))])\n",
    "elastic_net_pipeline_interaction = Pipeline(steps=[('preprocessor', combined_preprocessor), ('regressor', ElasticNetCV(random_state=42))])\n",
    "\n",
    "# List of pipelines for using the selected variables with interactions\n",
    "pipelines_interaction = [\n",
    "    ('Linear Regression', linear_pipeline_interaction),\n",
    "    ('Ridge Regression', ridge_pipeline_interaction),\n",
    "    ('Lasso Regression', lasso_pipeline_interaction),\n",
    "    ('Elastic Net Regression', elastic_net_pipeline_interaction)\n",
    "]\n",
    "\n",
    "# Extracting the training and testing data for the selected features\n",
    "X_train_interaction = X_train[numeric_features + categorical_features]\n",
    "X_test_interaction = X_test[numeric_features + categorical_features]\n",
    "\n",
    "# Evaluating each model using the selected variables with interactions\n",
    "interaction_results = {}\n",
    "for name, pipeline in pipelines_interaction:\n",
    "    mse = train_evaluate_model(pipeline, X_train_interaction, y_train, X_test_interaction, y_test)\n",
    "    interaction_results[name] = mse\n",
    "\n",
    "interaction_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668694b-5ea3-4bdf-bcd7-4f339ef659a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part III. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470001a-523f-4225-a39c-d45adfed73a9",
   "metadata": {},
   "source": [
    "A. Ridge\n",
    "\n",
    "The ridge model is slightly better than the ordinary regression model. The ridge model has a lower MSE and the absolute values of coefficients are smaller. It is because the regularization term in Ridge regression, which penalizes large coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d192ec1-f6df-48c8-9af8-1fbd1b247d6a",
   "metadata": {},
   "source": [
    "B. LASSO\n",
    "\n",
    "LASSO model in I with more variables has greater lambda comparing to the LASSO model in II with less variables. The presence of more variables introduces additional complexity and potential multicollinearity, which increase penalty and avoid overfitting. LASSO model in I has smaller MSE than models in II. A model with more explanatory variables might predit more precise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f612fb88-0fde-42e3-bc0e-9a290d94cf96",
   "metadata": {},
   "source": [
    "C. Elastic Net\n",
    "\n",
    "Elastic Net model added both squred and absolute value penalties. Elastic Net typically \"wins\" over Ridge and LASSO in scenarios where there are multiple features that are correlated with each other. In such cases, LASSO might randomly select only one feature among the correlated ones, while Ridge might include all but not identify the most important one. Elastic Net balances out this aspect by keeping a group of correlated variables together in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf73ff-9fee-4fca-a83b-a637ab8c655c",
   "metadata": {},
   "source": [
    "# Part IV: Final Model\n",
    "\n",
    "Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "70eee94c-65e9-4d64-a0f4-0b884b528b80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 75.86650664,  30.52886833,  95.63502864,  35.65444758,\n",
       "        97.8704077 ,  45.69767486, -45.69785527])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = ['CRuns', 'AtBat', 'Hits', 'CWalks', 'CRBI']\n",
    "categorical_features = ['Division']\n",
    "\n",
    "X = hitters_cleaned[numeric_features + categorical_features]\n",
    "y = hitters_cleaned['Salary']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "best_regression = ElasticNetCV(cv=5, random_state=0)\n",
    "\n",
    "best_elastic_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                        ('best_regression', best_regression)])\n",
    "best_model = best_elastic_pipeline.fit(X, y)\n",
    "\n",
    "coefs = best_model.named_steps['best_regression'].coef_\n",
    "\n",
    "feature_names = numeric_features.copy()\n",
    "\n",
    "ohe = best_model.named_steps['preprocessor'].named_transformers_['cat']\n",
    "\n",
    "feature_names.extend(ohe.get_feature_names_out(categorical_features))\n",
    "\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13e33582-009e-4cf1-a8d4-671e9c9db4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUmklEQVR4nO3de3zP9f//8fvbzNsOthljxtjJmTlGo8xECPEppXKMdHDKsUhlS1JKRFEpFuXwyako5DSdRiumyQiZOauPbE4b216/P/p5f73bxsxe3tvcrpfL63Lxfr6e7+fr8Xo/W9z3fL1eb4thGIYAAAAAAECBK+HoAgAAAAAAKK4I3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAD8S3R0tCwWS65bTEyMrW9AQID69etnSh3Hjh1TZGSk4uPjs+2LjIyUxWK54TH79esni8WiunXrKjMzM9t+i8WiIUOG5Kdcvfbaa1q5cuUNvSc1NVWTJk1S06ZN5eHhIavVqoCAAPXv31/bt2/PVx15lZSUpE6dOsnb21sWi0XDhw+XJO3YsUPh4eHy9PSUxWLR9OnTFRMTk23u8+LKf0tJSUkFXv/V8vPZAwBujZKOLgAAgMJq3rx5qlWrVrb2OnXq3JLjHzt2TFFRUQoICFDDhg3t9j3xxBPq0KFDvsfevXu3oqOjNWDAgJus8v+89tpr6t69u7p165an/gcOHNC9996rU6dO6emnn1ZUVJTc3d2VlJSk//73v2rSpInOnDkjT0/PAqvxaiNGjNC2bds0d+5c+fr6qlKlSpKk/v376/z581q8eLHKli2rgIAAubq6KjY29obnvlOnToqNjbWNbZYb/ewBALcOoRsAgFzUq1dPTZs2dXQZOapSpYqqVKmSr/e6ubmpcePGmjBhgh577DG5uLgUcHXXl5mZqf/85z/666+/FBsbq3r16tn2hYeHq2/fvlqzZo2cnZ1Nq2HXrl1q1qxZtqC6a9cuDRw4UB07drRrv/POO2/4GD4+PvLx8bmZMgEARRyXlwMAUIDS0tI0atQoNWzYUJ6envL29lZYWJi++OKLbH0///xzNW/eXJ6ennJ1dVVQUJD69+8vSYqJidEdd9whSXr88cdtl7ZHRkZKyv3y8oULFyosLEzu7u5yd3dXw4YN9fHHH2fr98Ybb+jo0aN65513rntOqampGj16tAIDA1WqVClVrlxZw4cP1/nz5219LBaLzp8/r08++cRWa+vWrXMdc+XKlUpISNC4cePsAvfVOnbsKFdXV9vr77//Xvfcc4/KlCkjV1dXtWjRQl999VW29504cUJPPfWUqlSpolKlSikwMFBRUVHKyMiQJNul4vv379eaNWts9V65FDwjI0OzZ8+2tV/9nn9fXr5t2zZ16dJF5cqVU+nSpRUcHGy7TF3K/fLyDRs26J577pGHh4dcXV3VsmVLbdy40a7PlTn+7bff9Oijj8rT01MVK1ZU//79lZKSkqfP/sKFC7a5K126tLy9vdW0aVMtWrQo17kBABQsVroBAMhFZmamLahdYbFY5OTklOt70tPTdfr0aY0ePVqVK1fWpUuXtGHDBj3wwAOaN2+e+vTpI0mKjY1Vjx491KNHD0VGRqp06dI6dOiQNm3aJElq3Lix5s2bp8cff1wvvviiOnXqJEnXXN1++eWXNXHiRD3wwAMaNWqUPD09tWvXLh06dChb37CwMP3nP//RG2+8oSeffFLe3t45jnnhwgWFh4fryJEjeuGFFxQaGqrffvtNL7/8shISErRhwwZZLBbFxsaqTZs2ioiI0EsvvSRJ8vDwyLXWb775RpLyfDn0li1b1K5dO4WGhurjjz+W1WrVrFmz1KVLFy1atEg9evSQ9E/gbtasmUqUKKGXX35ZwcHBio2N1auvvqqkpCTNmzdPjRs3VmxsrP7zn/8oODhYb731liQpMDBQsbGxCgsLU/fu3TVq1Khr1rRu3Tp16dJFtWvX1ttvv62qVasqKSnJdm65+fTTT9WnTx917dpVn3zyiZydnfXBBx+offv2Wrdune655x67/g8++KB69OihAQMG2H5RIUlz586VpGt+9iNHjtSCBQv06quvqlGjRjp//rx27dql//3vf3n63AEABcAAAAB25s2bZ0jKcXNycrLrW61aNaNv3765jpWRkWFcvnzZGDBggNGoUSNb+1tvvWVIMs6cOZPre+Pi4gxJxrx587LtmzBhgnH1X+N//PGH4eTkZPTs2fOa59a3b1/Dzc3NMAzD2LNnj+Hk5GSMGjXKtl+SMXjwYNvryZMnGyVKlDDi4uLsxlm6dKkhyfj6669tbW5ubtf8LK7WoUMHQ5KRlpaWp/533nmnUaFCBePs2bO2toyMDKNevXpGlSpVjKysLMMwDOOpp54y3N3djUOHDtm9/8rn/dtvv9naqlWrZnTq1Cnbsf79GRiGYWzevNmQZGzevNnWFhwcbAQHBxsXL17Mte4r/y0dPHjQMAzDOH/+vOHt7W106dLFrl9mZqbRoEEDo1mzZra2K3M8ZcoUu76DBg0ySpcubTtnw8j9s69Xr57RrVu3XOsDAJiPy8sBAMjF/PnzFRcXZ7dt27btuu/7/PPP1bJlS7m7u6tkyZJydnbWxx9/rMTERFufK5eOP/zww/rvf/+ro0eP3lSt69evV2ZmpgYPHpzn99SsWVMDBgzQu+++q+Tk5Bz7rF69WvXq1VPDhg2VkZFh29q3b5+vp3nnx/nz57Vt2zZ1795d7u7utnYnJyf17t1bR44c0d69e231RkREyM/Pz67eK/dnb9mypUBq+v3333XgwAENGDBApUuXzvP7fvzxR50+fVp9+/a1qy8rK0sdOnRQXFyc3WX7knT//ffbvQ4NDVVaWppOnTp13eM1a9ZMa9as0dixYxUTE6OLFy/muVYAQMEgdAMAkIvatWuradOmdluTJk2u+Z7ly5fr4YcfVuXKlfXpp58qNjZWcXFx6t+/v9LS0mz9WrVqpZUrVyojI0N9+vRRlSpVVK9evXzfa/vnn39Kuvbl5zmJjIyUk5OT7bLkfzt58qR+/fVXOTs7221lypSRYRj666+/8lVv1apVJUkHDx68bt+///5bhmHk+ARwPz8/SbJdLn3y5EmtWrUqW71169aVpHzX+2/5/bxPnjwpSerevXu2Gt944w0ZhqHTp0/bvadcuXJ2r61WqyTlKUDPmDFDzz//vFauXKmIiAh5e3urW7du2rdv3w3VDQDIP+7pBgCgAH366acKDAzUkiVL7B50lp6enq1v165d1bVrV6Wnp2vr1q2aPHmyHnvsMQUEBCgsLOyGjnvlCdlHjhyRv79/nt9XqVIlDR8+XK+//nqO9zCXL19eLi4utvuHc9qfH+3bt9eHH36olStXauzYsdfsW7ZsWZUoUULHjx/Ptu/YsWN2dZQvX16hoaGaNGlSjmNdCek36+rP+0ZcqXPmzJm5Pg29YsWKN1fcVdzc3BQVFaWoqCidPHnSturdpUsX7dmzp8COAwDIHaEbAIACZLFYVKpUKbvAfeLEiRyfXn6F1WpVeHi4vLy8tG7dOu3YsUNhYWE3tKJ57733ysnJSbNnz77hwP7888/rww8/zDH8du7cWa+99prKlSunwMDAa45jtVrzfPly165dVb9+fU2ePFmdO3fO8Qnm69at09133y03Nzc1b95cy5cv11tvvWX7irOsrCx9+umnqlKlimrUqGGr9+uvv1ZwcLDKli2bp1ryo0aNGgoODtbcuXM1cuRI21xdT8uWLeXl5aXdu3dryJAhBVZPXj77ihUrql+/ftq5c6emT5+uCxcu2D0dHgBgDkI3AAC52LVrV7anl0tScHBwrt+93LlzZy1fvlyDBg1S9+7ddfjwYU2cOFGVKlWyu6T35Zdf1pEjR3TPPfeoSpUqOnPmjN555x05OzsrPDzcdhwXFxd99tlnql27ttzd3eXn55fjam1AQIBeeOEFTZw4URcvXrR9xdTu3bv1119/KSoqKtfz9PDw0Pjx4zVixIhs+4YPH65ly5apVatWGjFihEJDQ5WVlaXk5GR98803GjVqlJo3by5Jql+/vmJiYrRq1SpVqlRJZcqUUc2aNXM8ppOTk1asWKF7771XYWFheuaZZxQRESE3NzcdOnRIS5cu1apVq/T3339LkiZPnqx27dopIiJCo0ePVqlSpTRr1izt2rVLixYtsv2S45VXXtH69evVokULDRs2TDVr1lRaWpqSkpL09ddf6/3338/395v/23vvvacuXbrozjvv1IgRI1S1alUlJydr3bp1+uyzz3J8j7u7u2bOnKm+ffvq9OnT6t69uypUqKA///xTO3fu1J9//qnZs2ffcC25ffbNmzdX586dFRoaqrJlyyoxMVELFixQWFgYgRsAbhUHP8gNAIBC51pPL5dkzJkzx9Y3p6eXv/7660ZAQIBhtVqN2rVrG3PmzMn2tPHVq1cbHTt2NCpXrmyUKlXKqFChgnHfffcZ3333nd1YixYtMmrVqmU4OzsbkowJEyYYhpH96eVXzJ8/37jjjjuM0qVLG+7u7kajRo3snn5+9dPLr5aenm4EBgbm+OTuc+fOGS+++KJRs2ZNo1SpUoanp6dRv359Y8SIEcaJEyds/eLj442WLVsarq6uhiQjPDz8eh+1cebMGWPixIlG48aNDXd3d8PZ2dmoWrWq0atXL+OHH36w6/vdd98Zbdq0Mdzc3AwXFxfjzjvvNFatWpVtzD///NMYNmyYERgYaDg7Oxve3t5GkyZNjPHjxxvnzp2z9bvZp5cbhmHExsYaHTt2NDw9PQ2r1WoEBwcbI0aMsO3/99PLr9iyZYvRqVMnw9vb23B2djYqV65sdOrUyfj8889tfa7M8Z9//mn33pzGzO2zHzt2rNG0aVOjbNmyhtVqNYKCgowRI0YYf/31V7bzBgCYw2IYhnGrgz4AAAAAALcDnl4OAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYpKSjC0DByMrK0rFjx1SmTBlZLBZHlwMAAAAAxZphGDp79qz8/PxUokTu69mE7mLi2LFj8vf3d3QZAAAAAHBbOXz4sKpUqZLrfkJ3MVGmTBlJ/0y4h4eHg6sBAAAAgOItNTVV/v7+tiyWG0J3MXHlknIPDw9CNwAAAADcIte7vZcHqQEAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASnl4OACgwTcbMd3QJAIDbzC9v9nF0CcA1sdINAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdkk6cOKGhQ4cqKChIVqtV/v7+6tKlizZu3ChJCggIkMVikcVikYuLi2rVqqU333xThmE4uHIAAAAAQGFW0tEFOFpSUpJatmwpLy8vTZkyRaGhobp8+bLWrVunwYMHa8+ePZKkV155RQMHDlRaWpo2bNigZ555Rh4eHnrqqaccfAYAAAAAgMLqtl/pHjRokCwWi3766Sd1795dNWrUUN26dTVy5Eht3brV1q9MmTLy9fVVQECAnnjiCYWGhuqbb76x7bdYLFq5cqXd2F5eXoqOjpb0T7i3WCxavny5IiIi5OrqqgYNGig2NtbW/9ChQ+rSpYvKli0rNzc31a1bV19//bWp5w8AAAAAMM9tHbpPnz6ttWvXavDgwXJzc8u238vLK1ubYRiKiYlRYmKinJ2db/iY48eP1+jRoxUfH68aNWro0UcfVUZGhiRp8ODBSk9P17fffquEhAS98cYbcnd3v+FjAAAAAAAKh9v68vL9+/fLMAzVqlXrun2ff/55vfjii7p06ZIuX76s0qVLa9iwYTd8zNGjR6tTp06SpKioKNWtW1f79+9XrVq1lJycrAcffFD169eXJAUFBeU6Tnp6utLT022vU1NTb7gWAAAAAIC5buuV7isPQrNYLNftO2bMGMXHx2vLli2KiIjQ+PHj1aJFixs+ZmhoqO3PlSpVkiSdOnVKkjRs2DC9+uqratmypSZMmKBff/0113EmT54sT09P2+bv73/DtQAAAAAAzHVbh+7q1avLYrEoMTHxun3Lly+vkJAQhYWFadmyZZo2bZo2bNhg22+xWLI9zfzy5cvZxrn6kvQrYT8rK0uS9MQTT+iPP/5Q7969lZCQoKZNm2rmzJk51jNu3DilpKTYtsOHD1//hAEAAAAAt9RtHbq9vb3Vvn17vffeezp//ny2/WfOnMnxfWXLltXQoUM1evRoW9D28fHR8ePHbX327dunCxcu3HBN/v7+evrpp7V8+XKNGjVKc+bMybGf1WqVh4eH3QYAAAAAKFxu69AtSbNmzVJmZqaaNWumZcuWad++fUpMTNSMGTMUFhaW6/sGDx6svXv3atmyZZKkNm3a6N1339X27dv1888/6+mnn77hB60NHz5c69at08GDB7V9+3Zt2rRJtWvXvqnzAwAAAAA4zm0fugMDA7V9+3ZFRERo1KhRqlevntq1a6eNGzdq9uzZub7Px8dHvXv3VmRkpLKysjR16lT5+/urVatWeuyxxzR69Gi5urreUC2ZmZkaPHiwateurQ4dOqhmzZqaNWvWzZ4iAAAAAMBBLMa/b0RGkZSamipPT0+lpKRwqTkAh2kyZr6jSwAA3GZ+ebOPo0vAbSqvGey2X+kGAAAAAMAshG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATFLS0QUAAIqPX97s4+gSAAAAChVWugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk5R0dAEAgOIj+ZX6ji4ByFHVlxMcXQIA4DbFSjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXTn4scff5STk5M6dOhg1x4ZGamGDRtm6x8QECCLxSKLxSInJyf5+flpwIAB+vvvv2/ouK1bt9bw4cNvonIAAAAAQGFB6M7F3LlzNXToUH3//fdKTk7O03teeeUVHT9+XMnJyfrss8/07bffatiwYSZXCgAAAAAorAjdOTh//rz++9//6plnnlHnzp0VHR0tSYqOjlZUVJR27txpW9W+sk+SypQpI19fX1WuXFkRERHq06ePtm/fbtv/v//9T48++qiqVKkiV1dX1a9fX4sWLbLt79evn7Zs2aJ33nnHNn5SUtItOmsAAAAAQEEjdOdgyZIlqlmzpmrWrKlevXpp3rx5MgxDPXr00KhRo1S3bl0dP35cx48fV48ePXIc4+jRo1q9erWaN29ua0tLS1OTJk20evVq7dq1S08++aR69+6tbdu2SZLeeecdhYWFaeDAgbbx/f39b8k5AwAAAAAKHqE7Bx9//LF69eolSerQoYPOnTunjRs3ysXFRe7u7ipZsqR8fX3l6+srFxcX2/uef/55ubu7y8XFRVWqVJHFYtHbb79t21+5cmWNHj1aDRs2VFBQkIYOHar27dvr888/lyR5enqqVKlScnV1tY3v5OSUY43p6elKTU212wAAAAAAhQuh+1/27t2rn376SY888ogkqWTJkurRo4fmzp173feOGTNG8fHx+vXXX7Vx40ZJUqdOnZSZmSlJyszM1KRJkxQaGqpy5crJ3d1d33zzTZ7vGb/a5MmT5enpadtYEQcAAACAwqekowsobD7++GNlZGSocuXKtjbDMOTs7HzdJ5GXL19eISEhkqTq1atr+vTpCgsL0+bNm9W2bVtNnTpV06ZN0/Tp01W/fn25ublp+PDhunTp0g3XOW7cOI0cOdL2OjU1leANAAAAAIUMofsqGRkZmj9/vqZOnap7773Xbt+DDz6ozz77TKVKlbKtXF/PlUvDL168KEn67rvv1LVrV9ul61lZWdq3b59q165te09ex7darbJarXmqAwAAAADgGITuq6xevVp///23BgwYIE9PT7t93bt318cff6wxY8bo4MGDio+PV5UqVVSmTBlb+D179qxOnDghwzB0+PBhPffccypfvrxatGghSQoJCdGyZcv0448/qmzZsnr77bd14sQJu9AdEBCgbdu2KSkpSe7u7vL29laJEtwFAAAAAABFEWnuKh9//LHatm2bLXBL/6x0x8fHKzg4WB06dFBERIR8fHzsvvLr5ZdfVqVKleTn56fOnTvLzc1N69evV7ly5SRJL730kho3bqz27durdevW8vX1Vbdu3eyOM3r0aDk5OalOnTry8fHJ1/3eAAAAAIDCwWIYhuHoInDzUlNT5enpqZSUFHl4eDi6HAC3qeRX6ju6BCBHVV9OcHQJAIBiJq8ZjJVuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATFLS0QUAAIqPqi8nOLoEAACAQoWVbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATFLS0QUAAIqPljNbOroEAABQiP0w9AdHl3DLsdINAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdt0B0dLS8vLwcXQYAAAAA4BYjdN+kfv36qVu3btnaY2JiZLFYdObMGfXo0UO///67bV9kZKQaNmx464oEAAAAADhESUcXcDtwcXGRi4uLo8sAAAAAANxirHTfAldfXh4dHa2oqCjt3LlTFotFFotF0dHRkv5ZAa9ataqsVqv8/Pw0bNgwxxUNAAAAALhprHTfYj169NCuXbu0du1abdiwQZLk6emppUuXatq0aVq8eLHq1q2rEydOaOfOnbmOk56ervT0dNvr1NRU02sHAAAAANwYQncBWL16tdzd3e3aMjMzc+zr4uIid3d3lSxZUr6+vrb25ORk+fr6qm3btnJ2dlbVqlXVrFmzXI85efJkRUVFFcwJAAAAAABMweXlBSAiIkLx8fF220cffXRDYzz00EO6ePGigoKCNHDgQK1YsUIZGRm59h83bpxSUlJs2+HDh2/2NAAAAAAABYyV7gLg5uamkJAQu7YjR47c0Bj+/v7au3ev1q9frw0bNmjQoEF68803tWXLFjk7O2frb7VaZbVab6puAAAAAIC5WOl2gFKlSuV4+bmLi4vuv/9+zZgxQzExMYqNjVVCQoIDKgQAAAAAFARWuh0gICBABw8eVHx8vKpUqaIyZcpo0aJFyszMVPPmzeXq6qoFCxbIxcVF1apVc3S5AAAAAIB8YqXbAR588EF16NBBERER8vHx0aJFi+Tl5aU5c+aoZcuWCg0N1caNG7Vq1SqVK1fO0eUCAAAAAPLJYhiG4egicPNSU1Pl6emplJQUeXh4OLocALepljNbOroEAABQiP0w9AdHl1Bg8prBWOkGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATFLS0QUAAIqPH4b+4OgSAAAAChVWugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk5R0dAEAgOJjS6twR5cAFArh325xdAkAgEKiwFa6z5w5U1BDAQAAAABQLOQrdL/xxhtasmSJ7fXDDz+scuXKqXLlytq5c2eBFQcAAAAAQFGWr9D9wQcfyN/fX5K0fv16rV+/XmvWrFHHjh01ZsyYAi0QAAAAAICiKl/3dB8/ftwWulevXq2HH35Y9957rwICAtS8efMCLRAAAAAAgKIqXyvdZcuW1eHDhyVJa9euVdu2bSVJhmEoMzOz4KoDAAAAAKAIy9dK9wMPPKDHHntM1atX1//+9z917NhRkhQfH6+QkJACLRAAAAAAgKIqX6F72rRpCggI0OHDhzVlyhS5u7tL+uey80GDBhVogQAAAAAAFFX5Ct3Ozs4aPXp0tvbhw4ffbD0AAAAAABQb+f6e7gULFuiuu+6Sn5+fDh06JEmaPn26vvjiiwIrDgAAAACAoixfoXv27NkaOXKkOnbsqDNnztgenubl5aXp06cXZH0AAAAAABRZ+QrdM2fO1Jw5czR+/Hg5OTnZ2ps2baqEhIQCKw4AAAAAgKIsX6H74MGDatSoUbZ2q9Wq8+fP33RRAAAAAAAUB/kK3YGBgYqPj8/WvmbNGtWpU+dmawIAAAAAoFjI19PLx4wZo8GDBystLU2GYeinn37SokWLNHnyZH300UcFXSMAAAAAAEVSvkL3448/royMDD333HO6cOGCHnvsMVWuXFnvvPOOHnnkkYKuEQAAAACAIumGQ3dGRoY+++wzdenSRQMHDtRff/2lrKwsVahQwYz6AAAAAAAosm74nu6SJUvqmWeeUXp6uiSpfPnyBG4AAAAAAHKQrwepNW/eXDt27CjoWgAAAAAAKFbydU/3oEGDNGrUKB05ckRNmjSRm5ub3f7Q0NACKQ4AAAAAgKIsX6G7R48ekqRhw4bZ2iwWiwzDkMViUWZmZsFUBwAAAABAEZav0H3w4MGCrgMAAAAAgGInX6G7WrVqBV0HAAAAAADFTr5C9/z586+5v0+fPvkqpriJjIzUypUrFR8fL0nq16+fzpw5o5UrVzq0LgAAAADArZGv0P3ss8/avb58+bIuXLigUqVKydXVtVCG7hMnTmjSpEn66quvdPToUVWoUEENGzbU8OHDNWfOHKWkpGjNmjW2/mvWrNF9992nF198URMnTrS1T5w4UbNnz9axY8cccRoAAAAAgCIkX18Z9vfff9tt586d0969e3XXXXdp0aJFBV3jTUtKSlKTJk20adMmTZkyRQkJCVq7dq0iIiI0ePBgRURE6Pvvv1dGRobtPTExMfL399fmzZvtxoqJiVFERMStPgUAAAAAQBGUr9Cdk+rVq+v111/PtgpeGAwaNEgWi0U//fSTunfvrho1aqhu3boaOXKktm7dqoiICJ07d04///yz7T0xMTEaO3as4uLidOHCBUnSpUuXFBsbawvdzz//vGrUqCFXV1cFBQXppZde0uXLl/Nc1y+//KIKFSpo0qRJkqSdO3cqIiJCZcqUkYeHh5o0aWJXEwAAAACgaCmw0C1JTk5Ohe6y69OnT2vt2rUaPHhwtu8TlyQvLy/VqFFDfn5+tlXts2fPavv27XrooYcUHBysH374QZK0detWXbx40Ra6y5Qpo+joaO3evVvvvPOO5syZo2nTpuWprpiYGN1zzz2KiorS+PHjJUk9e/ZUlSpVFBcXp19++UVjx46Vs7NzQXwMAAAAAAAHyNc93V9++aXda8MwdPz4cb377rtq2bJlgRRWUPbv3y/DMFSrVq1r9mvdurViYmI0btw4fffdd6pRo4Z8fHwUHh6umJgYtWvXznbJeXBwsCTpxRdftL0/ICBAo0aN0pIlS/Tcc89d81hffPGFevfurQ8++ECPPvqorT05OVljxoyx1Vq9evVcx0hPT1d6errtdWpq6jWPCQAAAAC49fIVurt162b32mKxyMfHR23atNHUqVMLoq4CYxiGpH9qvJaIiAgNHz5cly9fVkxMjFq3bi1JCg8P18yZMyX9szrdpk0b23uWLl2q6dOna//+/Tp37pwyMjLk4eFxzeNs27ZNq1ev1ueff67//Oc/dvtGjhypJ554QgsWLFDbtm1tK+05mTx5sqKioq55LAAAAACAY+Xr8vKsrCy7LTMzUydOnNDChQtVqVKlgq7xplSvXl0Wi0WJiYnX7BcREaHz588rLi5OmzdvVnh4uKR/QndcXJxOnz5tdz/31q1b9cgjj6hjx45avXq1duzYofHjx+vSpUvXPE5wcLBq1aqluXPnZusbGRmp3377TZ06ddKmTZtUp04drVixIsdxxo0bp5SUFNt2+PDhvH4kAAAAAIBbJF+h+5VXXrE9XOxqFy9e1CuvvHLTRRUkb29vtW/fXu+9957Onz+fbf+ZM2ck/ROG/f399eWXXyo+Pt4WuitVqqSAgABNnTpVaWlpttD9ww8/qFq1aho/fryaNm2q6tWr69ChQ9etp3z58tq0aZMOHDigHj16ZHvwWo0aNTRixAh98803euCBBzRv3rwcx7FarfLw8LDbAAAAAACFS75Cd1RUlM6dO5et/cKFC4XykudZs2YpMzNTzZo107Jly7Rv3z4lJiZqxowZCgsLs/WLiIjQrFmzFBISoooVK9rar1xiHhQUpKpVq0qSQkJClJycrMWLF+vAgQOaMWNGrqvS/1ahQgVt2rRJe/bs0aOPPqqMjAxdvHhRQ4YMUUxMjA4dOqQffvhBcXFxql27dsF+GAAAAACAWyZfodswjBzvkd65c6e8vb1vuqiCFhgYqO3btysiIkKjRo1SvXr11K5dO23cuFGzZ8+29YuIiNDZs2dt93NfER4errNnz9p9P3fXrl01YsQIDRkyRA0bNtSPP/6ol156Kc81+fr6atOmTUpISFDPnj1VokQJ/e9//1OfPn1Uo0YNPfzww+rYsWOh/CUGAAAAACBvLMaVJ43lQdmyZWWxWJSSkiIPDw+74J2Zmalz587p6aef1nvvvWdKschdamqqPD09bXMDAI6wpVW4o0sACoXwb7c4ugQAgMnymsFu6Onl06dPl2EY6t+/v6KiouTp6WnbV6pUKQUEBNhdrg0AAAAAwO3shkJ33759Jf1zuXaLFi3k7OxsSlEAAAAAABQH+fqe7itP9pb+eWL5v5/AzeXNAAAAAADk80FqFy5c0JAhQ1ShQgW5u7urbNmydhsAAAAAAMhn6B4zZow2bdqkWbNmyWq16qOPPlJUVJT8/Pw0f/78gq4RAAAAAIAiKV+Xl69atUrz589X69at1b9/f919990KCQlRtWrV9Nlnn6lnz54FXScAAAAAAEVOvla6T58+rcDAQEn/3L99+vRpSdJdd92lb7/9tuCqAwAAAACgCMtX6A4KClJSUpIkqU6dOvrvf/8r6Z8VcC8vr4KqDQAAAACAIi1fofvxxx/Xzp07JUnjxo2z3ds9YsQIjRkzpkALBAAAAACgqMrXPd0jRoyw/TkiIkJ79uzRzz//rODgYDVo0KDAigMAAAAAoCjLV+i+WlpamqpWraqqVasWRD0AAAAAABQb+bq8PDMzUxMnTlTlypXl7u6uP/74Q5L00ksv6eOPPy7QAgEAAAAAKKryFbonTZqk6OhoTZkyRaVKlbK1169fXx999FGBFQcAAAAAQFGWr9A9f/58ffjhh+rZs6ecnJxs7aGhodqzZ0+BFQcAAAAAQFGWr9B99OhRhYSEZGvPysrS5cuXb7ooAAAAAACKg3yF7rp16+q7777L1v7555+rUaNGN10UAAAAAADFQb6eXj5hwgT17t1bR48eVVZWlpYvX669e/dq/vz5Wr16dUHXCAAAAABAkXRDK91//PGHDMNQly5dtGTJEn399deyWCx6+eWXlZiYqFWrVqldu3Zm1QoAAAAAQJFyQyvd1atX1/Hjx1WhQgW1b99ec+fO1f79++Xr62tWfQAAAAAAFFk3tNJtGIbd6zVr1ujChQsFWhAAAAAAAMVFvh6kdsW/QzgAAAAAAPg/NxS6LRaLLBZLtjYAAAAAAJDdDd3TbRiG+vXrJ6vVKklKS0vT008/LTc3N7t+y5cvL7gKAQBFRvi3WxxdAgAAQKFyQ6G7b9++dq979epVoMUAAAAAAFCc3FDonjdvnll1AAAAAABQ7NzUg9QAAAAAAEDuCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYpKSjCwAAFB/vjlrl6BIAAEAxM2RqF0eXcFNY6QYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhO4bcOLECQ0dOlRBQUGyWq3y9/dXly5dtHHjRklSQECALBaLLBaLXFxcVKtWLb355psyDMM2RlJSkq2PxWJRqVKlFBISoldffdWuX2RkpBo2bHirTxEAAAAAUIBKOrqAoiIpKUktW7aUl5eXpkyZotDQUF2+fFnr1q3T4MGDtWfPHknSK6+8ooEDByotLU0bNmzQM888Iw8PDz311FN2423YsEF169ZVenq6vv/+ez3xxBOqVKmSBgwY4IjTAwAAAACYgNCdR4MGDZLFYtFPP/0kNzc3W3vdunXVv39/2+syZcrI19dXkvTEE09o9uzZ+uabb7KF7nLlytn6VatWTXPnztX27dsJ3QAAAABQjHB5eR6cPn1aa9eu1eDBg+0C9xVeXl7Z2gzDUExMjBITE+Xs7HzN8X/++Wdt375dzZs3L6iSAQAAAACFACvdebB//34ZhqFatWpdt+/zzz+vF198UZcuXdLly5dVunRpDRs2LFu/Fi1aqESJErZ+Tz75pPr06ZPnmtLT05Wenm57nZqamuf3AgAAAABuDVa68+DKA84sFst1+44ZM0bx8fHasmWLIiIiNH78eLVo0SJbvyVLlig+Pl47d+7UkiVL9MUXX2js2LF5rmny5Mny9PS0bf7+/nk/IQAAAADALUHozoPq1avLYrEoMTHxun3Lly+vkJAQhYWFadmyZZo2bZo2bNiQrZ+/v79CQkJUu3ZtPfzwwxo+fLimTp2qtLS0PNU0btw4paSk2LbDhw/f8HkBAAAAAMxF6M4Db29vtW/fXu+9957Onz+fbf+ZM2dyfF/ZsmU1dOhQjR492u7rwHLi5OSkjIwMXbp0KU81Wa1WeXh42G0AAAAAgMKF0J1Hs2bNUmZmppo1a6Zly5Zp3759SkxM1IwZMxQWFpbr+wYPHqy9e/dq2bJldu3/+9//dOLECR05ckRr1qzRO++8o4iICMIzAAAAABQjPEgtjwIDA7V9+3ZNmjRJo0aN0vHjx+Xj46MmTZpo9uzZub7Px8dHvXv3VmRkpB544AFbe9u2bSX9s8JdqVIl3XfffZo0aZLp5wEAAAAAuHUsxvWue0aRkJqaKk9PT6WkpLBaDsBh3h21ytElAACAYmbI1C6OLiFHec1gXF4OAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASUo6ugAAQPExZGoXR5cAAABQqLDSDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASUo6ugAAQPExqVd3R5cAwGTjP13q6BIAoEhhpRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTFNnQbbFYtHLlyjz3DwgI0PTp0wu8LwAAAAAAuSl0obtfv36yWCyyWCxydnZWxYoV1a5dO82dO1dZWVm2fsePH1fHjh3zPG5cXJyefPLJAu9bEK4+56u3Dh063LIaAAAAAAAFr6SjC8hJhw4dNG/ePGVmZurkyZNau3atnn32WS1dulRffvmlSpYsKV9f3xsa08fHx5S+BeXKOV/NarXe8joAAAAAAAWn0K10S/+ETV9fX1WuXFmNGzfWCy+8oC+++EJr1qxRdHS0JPvLy8PCwjR27Fi7Mf788085Oztr8+bNkrJfMh4ZGamqVavKarXKz89Pw4YNs+37d9/k5GR17dpV7u7u8vDw0MMPP6yTJ0/ajdWwYUMtWLBAAQEB8vT01COPPKKzZ8/e8DlfvZUtWzbP7wcAAAAAFD6FMnTnpE2bNmrQoIGWL1+ebV/Pnj21aNEiGYZha1uyZIkqVqyo8PDwbP2XLl2qadOm6YMPPtC+ffu0cuVK1a9fP8fjGoahbt266fTp09qyZYvWr1+vAwcOqEePHnb9Dhw4oJUrV2r16tVavXq1tmzZotdff/0mzzp36enpSk1NtdsAAAAAAIVLkQndklSrVi0lJSVla+/Ro4eOHTum77//3ta2cOFCPfbYYypRIvspJicny9fXV23btlXVqlXVrFkzDRw4MMdjbtiwQb/++qsWLlyoJk2aqHnz5lqwYIG2bNmiuLg4W7+srCxFR0erXr16uvvuu9W7d29t3Lgxz+e2evVqubu7220TJ07Mtf/kyZPl6elp2/z9/fN8LAAAAADArVGkQrdhGLJYLNnafXx81K5dO3322WeSpIMHDyo2NlY9e/bMcZyHHnpIFy9eVFBQkAYOHKgVK1YoIyMjx76JiYny9/e3C7V16tSRl5eXEhMTbW0BAQEqU6aM7XWlSpV06tSpPJ9bRESE4uPj7bbBgwfn2n/cuHFKSUmxbYcPH87zsQAAAAAAt0aRCt2JiYkKDAzMcV/Pnj21dOlSXb58WQsXLlTdunXVoEGDHPv6+/tr7969eu+99+Ti4qJBgwapVatWunz5cra+uQX9f7c7Ozvb7bdYLHZPW78eNzc3hYSE2G3e3t659rdarfLw8LDbAAAAAACFS5EJ3Zs2bVJCQoIefPDBHPd369ZNaWlpWrt2rRYuXKhevXpdczwXFxfdf//9mjFjhmJiYhQbG6uEhIRs/erUqaPk5GS7leTdu3crJSVFtWvXvrmTAgAAAAAUa4XyK8PS09N14sQJu68Mmzx5sjp37qw+ffrk+B43Nzd17dpVL730khITE/XYY4/lOn50dLQyMzPVvHlzubq6asGCBXJxcVG1atWy9W3btq1CQ0PVs2dPTZ8+XRkZGRo0aJDCw8PVtGnTAj/nq5UsWVLly5cvsGMAAAAAAG6tQhm6165dq0qVKqlkyZIqW7asGjRooBkzZqhv3745Phjtip49e6pTp05q1aqVqlatmms/Ly8vvf766xo5cqQyMzNVv359rVq1SuXKlcvW98pXkw0dOlStWrVSiRIl1KFDB82cObNAzvWKK+d8tZo1a2rPnj0FehwAAAAAwK1jMa7+ni0UWampqfL09FRKSgr3dwNwmEm9uju6BAAmG//pUkeXAACFQl4zWJG5pxsAAAAAgKKG0G2y5OTkbN+/ffWWnJzs6BIBAAAAACYplPd0Fyd+fn6Kj4+/5n4AAAAAQPFE6DZZyZIlFRIS4ugyAAAAAAAOwOXlAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASUo6ugAAQPEx/tOlji4BAACgUGGlGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwSUlHF4DbQ+KkTY4uAcAtUHt8G0eXAAAAUKiw0g0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYpEiEbovFopUrV+a5f0BAgKZPn17gfQEAAAAAuBEODd39+vWTxWKRxWKRs7OzKlasqHbt2mnu3LnKysqy9Tt+/Lg6duyY53Hj4uL05JNPFnjfm/X++++rTJkyysjIsLWdO3dOzs7Ouvvuu+36fvfdd7JYLPr9999vSW0AAAAAgILn8JXuDh066Pjx40pKStKaNWsUERGhZ599Vp07d7aFU19fX1mt1jyP6ePjI1dX1wLve7MiIiJ07tw5/fzzz7a27777Tr6+voqLi9OFCxds7TExMfLz81ONGjVuSW0AAAAAgILn8NBttVrl6+urypUrq3HjxnrhhRf0xRdfaM2aNYqOjpZkf3l5WFiYxo4dazfGn3/+KWdnZ23evFlS9kvGIyMjVbVqVVmtVvn5+WnYsGG2ff/um5ycrK5du8rd3V0eHh56+OGHdfLkSbuxGjZsqAULFiggIECenp565JFHdPbs2euea82aNeXn56eYmBhbW0xMjLp27arg4GD9+OOPdu0RERHXHRMAAAAAUHg5PHTnpE2bNmrQoIGWL1+ebV/Pnj21aNEiGYZha1uyZIkqVqyo8PDwbP2XLl2qadOm6YMPPtC+ffu0cuVK1a9fP8fjGoahbt266fTp09qyZYvWr1+vAwcOqEePHnb9Dhw4oJUrV2r16tVavXq1tmzZotdffz1P59a6dWvbLwckafPmzWrdurXCw8Nt7ZcuXVJsbCyhGwAAAACKuJKOLiA3tWrV0q+//pqtvUePHhoxYoS+//57233QCxcu1GOPPaYSJbL/DiE5OVm+vr5q27atnJ2dVbVqVTVr1izHY27YsEG//vqrDh48KH9/f0nSggULVLduXcXFxemOO+6QJGVlZSk6OlplypSRJPXu3VsbN27UpEmTrnterVu31ogRI5SRkaGLFy9qx44datWqlTIzMzVjxgxJ0tatW3Xx4sVrhu709HSlp6fbXqempl732AAAAACAW6tQrnRL/6w6WyyWbO0+Pj5q166dPvvsM0nSwYMHFRsbq549e+Y4zkMPPaSLFy8qKChIAwcO1IoVK+weZHa1xMRE+fv72wK3JNWpU0deXl5KTEy0tQUEBNgCtyRVqlRJp06dytN5RURE6Pz584qLi9N3332nGjVqqEKFCgoPD1dcXJzOnz+vmJgYVa1aVUFBQbmOM3nyZHl6etq2q2sGAAAAABQOhTZ0JyYmKjAwMMd9PXv21NKlS3X58mUtXLhQdevWVYMGDXLs6+/vr7179+q9996Ti4uLBg0apFatWuny5cvZ+uYW9P/d7uzsbLffYrHYPW39WkJCQlSlShVt3rxZmzdvtl0S7+vrq8DAQP3www/avHmz2rRpc81xxo0bp5SUFNt2+PDhPB0fAAAAAHDrFMrQvWnTJiUkJOjBBx/McX+3bt2UlpamtWvXauHCherVq9c1x3NxcdH999+vGTNmKCYmRrGxsUpISMjWr06dOkpOTrYLsLt371ZKSopq1659cyd1lYiICMXExCgmJkatW7e2tYeHh2vdunXaunXrde/ntlqt8vDwsNsAAAAAAIWLw+/pTk9P14kTJ5SZmamTJ09q7dq1mjx5sjp37qw+ffrk+B43Nzd17dpVL730khITE/XYY4/lOn50dLQyMzPVvHlzubq6asGCBXJxcVG1atWy9W3btq1CQ0PVs2dPTZ8+XRkZGRo0aJDCw8PVtGnTAjvniIgIDR48WJcvX7Z7+Ft4eLieeeYZpaWl8RA1AAAAACgGHL7SvXbtWlWqVEkBAQHq0KGDNm/erBkzZuiLL76Qk5NTru/r2bOndu7cqbvvvltVq1bNtZ+Xl5fmzJmjli1bKjQ0VBs3btSqVatUrly5bH2vfDVZ2bJl1apVK7Vt21ZBQUFasmRJgZzrFREREbp48aJCQkJUsWJFW3t4eLjOnj2r4OBg7tEGAAAAgGLAYlz93VsoslJTU+Xp6amUlJRCeal54qRNji4BwC1Qe/y1n0cBAABQXOQ1gzl8pRsAAAAAgOKK0F2AkpOT5e7unuuWnJzs6BIBAAAAALeQwx+kVpz4+fkpPj7+mvsBAAAAALcPQncBKlmypEJCQhxdBgAAAACgkODycgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCQlHV0Abg+1x7dxdAkAAAAAcMux0g0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiErwwrJgzDkCSlpqY6uBIAAAAAKP6uZK8rWSw3hO5i4uzZs5Ikf39/B1cCAAAAALePs2fPytPTM9f9FuN6sRxFQlZWlo4dO6YyZcrIYrE4upxCJTU1Vf7+/jp8+LA8PDwcXQ7ygDkrmpi3ooc5K5qYt6KHOSuamLei51bPmWEYOnv2rPz8/FSiRO53brPSXUyUKFFCVapUcXQZhZqHhwf/wyximLOiiXkrepizool5K3qYs6KJeSt6buWcXWuF+woepAYAAAAAgEkI3QAAAAAAmITQjWLParVqwoQJslqtji4FecScFU3MW9HDnBVNzFvRw5wVTcxb0VNY54wHqQEAAAAAYBJWugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbxV56eroaNmwoi8Wi+Ph4u33Jycnq0qWL3NzcVL58eQ0bNkyXLl1yTKFQUlKSBgwYoMDAQLm4uCg4OFgTJkzINifMW+Eza9YsBQYGqnTp0mrSpIm+++47R5eE/2/y5Mm64447VKZMGVWoUEHdunXT3r177foYhqHIyEj5+fnJxcVFrVu31m+//eagipGTyZMny2KxaPjw4bY25q3wOXr0qHr16qVy5crJ1dVVDRs21C+//GLbz5wVPhkZGXrxxRdt//YICgrSK6+8oqysLFsf5s3xvv32W3Xp0kV+fn6yWCxauXKl3f68zFF6erqGDh2q8uXLy83NTffff7+OHDlyS+ondKPYe+655+Tn55etPTMzU506ddL58+f1/fffa/HixVq2bJlGjRrlgCohSXv27FFWVpY++OAD/fbbb5o2bZref/99vfDCC7Y+zFvhs2TJEg0fPlzjx4/Xjh07dPfdd6tjx45KTk52dGmQtGXLFg0ePFhbt27V+vXrlZGRoXvvvVfnz5+39ZkyZYrefvttvfvuu4qLi5Ovr6/atWuns2fPOrByXBEXF6cPP/xQoaGhdu3MW+Hy999/q2XLlnJ2dtaaNWu0e/duTZ06VV5eXrY+zFnh88Ybb+j999/Xu+++q8TERE2ZMkVvvvmmZs6caevDvDne+fPn1aBBA7377rs57s/LHA0fPlwrVqzQ4sWL9f333+vcuXPq3LmzMjMzzT8BAyjGvv76a6NWrVrGb7/9ZkgyduzYYbevRIkSxtGjR21tixYtMqxWq5GSkuKAapGTKVOmGIGBgbbXzFvh06xZM+Ppp5+2a6tVq5YxduxYB1WEazl16pQhydiyZYthGIaRlZVl+Pr6Gq+//rqtT1pamuHp6Wm8//77jioT/9/Zs2eN6tWrG+vXrzfCw8ONZ5991jAM5q0wev7554277ror1/3MWeHUqVMno3///nZtDzzwgNGrVy/DMJi3wkiSsWLFCtvrvMzRmTNnDGdnZ2Px4sW2PkePHjVKlChhrF271vSaWelGsXXy5EkNHDhQCxYskKura7b9sbGxqlevnt0qePv27ZWenm53KRgcKyUlRd7e3rbXzFvhcunSJf3yyy+699577drvvfde/fjjjw6qCteSkpIiSbafq4MHD+rEiRN2c2i1WhUeHs4cFgKDBw9Wp06d1LZtW7t25q3w+fLLL9W0aVM99NBDqlChgho1aqQ5c+bY9jNnhdNdd92ljRs36vfff5ck7dy5U99//73uu+8+ScxbUZCXOfrll190+fJluz5+fn6qV6/eLZnHkqYfAXAAwzDUr18/Pf3002ratKmSkpKy9Tlx4oQqVqxo11a2bFmVKlVKJ06cuEWV4loOHDigmTNnaurUqbY25q1w+euvv5SZmZltTipWrMh8FEKGYWjkyJG66667VK9ePUmyzVNOc3jo0KFbXiP+z+LFi7V9+3bFxcVl28e8FT5//PGHZs+erZEjR+qFF17QTz/9pGHDhslqtapPnz7MWSH1/PPPKyUlRbVq1ZKTk5MyMzM1adIkPfroo5L4WSsK8jJHJ06cUKlSpVS2bNlsfW7Fv1dY6UaREhkZKYvFcs3t559/1syZM5Wamqpx48ZdczyLxZKtzTCMHNuRf3mdt6sdO3ZMHTp00EMPPaQnnnjCbh/zVvj8+7NnPgqnIUOG6Ndff9WiRYuy7WMOC5fDhw/r2Wef1aeffqrSpUvn2o95KzyysrLUuHFjvfbaa2rUqJGeeuopDRw4ULNnz7brx5wVLkuWLNGnn36qhQsXavv27frkk0/01ltv6ZNPPrHrx7wVfvmZo1s1j6x0o0gZMmSIHnnkkWv2CQgI0KuvvqqtW7fKarXa7WvatKl69uypTz75RL6+vtq2bZvd/r///luXL1/O9psy3Jy8ztsVx44dU0REhMLCwvThhx/a9WPeCpfy5cvLyckp22+JT506xXwUMkOHDtWXX36pb7/9VlWqVLG1+/r6SvpnFaBSpUq2dubQsX755RedOnVKTZo0sbVlZmbq22+/1bvvvmt7Aj3zVnhUqlRJderUsWurXbu2li1bJomftcJqzJgxGjt2rO3fKfXr19ehQ4c0efJk9e3bl3krAvIyR76+vrp06ZL+/vtvu9XuU6dOqUWLFqbXyEo3ipTy5curVq1a19xKly6tGTNmaOfOnYqPj1d8fLy+/vprSf/8NnPSpEmSpLCwMO3atUvHjx+3jf/NN9/IarXa/SMHNy+v8yb983UrrVu3VuPGjTVv3jyVKGH/vynmrXApVaqUmjRpovXr19u1r1+//pb8JYbrMwxDQ4YM0fLly7Vp0yYFBgba7Q8MDJSvr6/dHF66dElbtmxhDh3onnvuUUJCgu3vsfj4eNsvjuPj4xUUFMS8FTItW7bM9nV8v//+u6pVqyaJn7XC6sKFC9n+reHk5GT7yjDmrfDLyxw1adJEzs7Odn2OHz+uXbt23Zp5NP1RbUAhcPDgwWxPL8/IyDDq1atn3HPPPcb27duNDRs2GFWqVDGGDBniuEJvc0ePHjVCQkKMNm3aGEeOHDGOHz9u265g3gqfxYsXG87OzsbHH39s7N692xg+fLjh5uZmJCUlObo0GIbxzDPPGJ6enkZMTIzdz9SFCxdsfV5//XXD09PTWL58uZGQkGA8+uijRqVKlYzU1FQHVo5/u/rp5YbBvBU2P/30k1GyZElj0qRJxr59+4zPPvvMcHV1NT799FNbH+as8Onbt69RuXJlY/Xq1cbBgweN5cuXG+XLlzeee+45Wx/mzfHOnj1r7Nixw9ixY4chyXj77beNHTt2GIcOHTIMI29z9PTTTxtVqlQxNmzYYGzfvt1o06aN0aBBAyMjI8P0+gnduC3kFLoNwzAOHTpkdOrUyXBxcTG8vb2NIUOGGGlpaY4pEsa8efMMSTluV2PeCp/33nvPqFatmlGqVCmjcePGtq+jguPl9jM1b948W5+srCxjwoQJhq+vr2G1Wo1WrVoZCQkJjisaOfp36GbeCp9Vq1YZ9erVM6xWq1GrVi3jww8/tNvPnBU+qampxrPPPmtUrVrVKF26tBEUFGSMHz/eSE9Pt/Vh3hxv8+bNOf5d1rdvX8Mw8jZHFy9eNIYMGWJ4e3sbLi4uRufOnY3k5ORbUr/FMAzD/PV0AAAAAABuP9zTDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAkSSdOnFC7du3k5uYmLy+vXNssFotWrlyZpzEjIyPVsGFDU+q9FYp6/QAAxyN0AwBQyJ04cUJDhw5VUFCQrFar/P391aVLF23cuLFAjzNt2jQdP35c8fHx+v3333NtO378uDp27JinMUePHl3gdUZHR9t+AZCbqVOnytPTUxcuXMi2Ly0tTV5eXnr77bcLtC4AAHJC6AYAoBBLSkpSkyZNtGnTJk2ZMkUJCQlau3atIiIiNHjw4AI91oEDB9SkSRNVr15dFSpUyLXN19dXVqs1T2O6u7urXLlyBVpnXvTp00cXL17UsmXLsu1btmyZLly4oN69e9/yugAAtx9CNwAAhdigQYNksVj0008/qXv37qpRo4bq1q2rkSNHauvWrbZ+ycnJ6tq1q9zd3eXh4aGHH35YJ0+etBtr1apVatKkiUqXLq2goCBFRUUpIyNDkhQQEKBly5Zp/vz5slgs6tevX45tUvbLy48cOaJHHnlE3t7ecnNzU9OmTbVt2zZJOV+ePW/ePNWuXVulS5dWrVq1NGvWLNu+pKQkWSwWLV++XBEREXJ1dVWDBg0UGxsrSYqJidHjjz+ulJQUWSwWWSwWRUZGZvvcfHx81KVLF82dOzfbvrlz5+r++++Xj4+Pnn/+edWoUUOurq4KCgrSSy+9pMuXL+c6H61bt9bw4cPt2rp162b7bCTp0qVLeu6551S5cmW5ubmpefPmiomJyXVMAEDxVtLRBQAAgJydPn1aa9eu1aRJk+Tm5pZt/5VLrA3DULdu3eTm5qYtW7YoIyNDgwYNUo8ePWxhb926derVq5dmzJihu+++WwcOHNCTTz4pSZowYYLi4uLUp08feXh46J133pGLi4suXbqUre3fzp07p/DwcFWuXFlffvmlfH19tX37dmVlZeV4TnPmzNGECRP07rvvqlGjRtqxY4cGDhwoNzc39e3b19Zv/Pjxeuutt1S9enWNHz9ejz76qPbv368WLVpo+vTpevnll7V3715J/6ym52TAgAHq3LmzDh48qMDAQEn/hPrNmzfrq6++kiSVKVNG0dHR8vPzU0JCggYOHKgyZcroueeey8MM5ezxxx9XUlKSFi9eLD8/P61YsUIdOnRQQkKCqlevnu9xAQBFE6EbAIBCav/+/TIMQ7Vq1bpmvw0bNujXX3/VwYMH5e/vL0lasGCB6tatq7i4ON1xxx2aNGmSxo4dawu2QUFBmjhxop577jlNmDBBPj4+slqtcnFxka+vr23snNqutnDhQv3555+Ki4uTt7e3JCkkJCTXWidOnKipU6fqgQcekCQFBgZq9+7d+uCDD+xC9+jRo9WpUydJUlRUlOrWrav9+/erVq1a8vT0lMViybWmK9q3by8/Pz9FR0crKipK0j+r7H5+frr33nslSS+++KKtf0BAgEaNGqUlS5bkO3QfOHBAixYt0pEjR+Tn52c7l7Vr12revHl67bXX8jUuAKDoInQDAFBIGYYh6Z/Lua8lMTFR/v7+tsAtSXXq1JGXl5cSExN1xx136JdfflFcXJwmTZpk65OZmam0tDRduHBBrq6u+aoxPj5ejRo1sgXua/nzzz91+PBhDRgwQAMHDrS1Z2RkyNPT065vaGio7c+VKlWSJJ06deq6v4C4mpOTk/r27avo6GhNmDBBFotFn3zyifr16ycnJydJ0tKlSzV9+nTt379f586dU0ZGhjw8PPJ8jH/bvn27DMNQjRo17NrT09Mdcm87AMDxCN0AABRS1atXl8ViUWJiorp165ZrP8MwcgzmV7dnZWUpKirKtsJ8tdKlS+e7xpwuOc/NlUvO58yZo+bNm9vtuxKCr3B2drb9+epzuFH9+/fX5MmTtWnTJkn/3Pv++OOPS5K2bt2qRx55RFFRUWrfvr08PT21ePFiTZ06NdfxSpQoYftlyBVX3wOelZUlJycn/fLLL9nOKbfL4AEAxRuhGwCAQsrb21vt27fXe++9p2HDhmW7r/vMmTPy8vJSnTp1lJycrMOHD9tWu3fv3q2UlBTVrl1bktS4cWPt3bv3mpd+50doaKg++ugjnT59+rqr3RUrVlTlypX1xx9/qGfPnvk+ZqlSpZSZmZmnvsHBwQoPD9e8efNkGIZat26t4OBgSdIPP/ygatWqafz48bb+hw4duuZ4Pj4+On78uO11Zmamdu3apYiICElSo0aNlJmZqVOnTunuu+++0VMDABRDPL0cAIBCbNasWcrMzFSzZs20bNky7du3T4mJiZoxY4bCwsIkSW3btlVoaKh69uyp7du366efflKfPn0UHh6upk2bSpJefvllzZ8/X5GRkfrtt9+UmJioJUuW2N3TnB+PPvqofH191a1bN/3www/6448/tGzZMtvTxv8tMjJSkydP1jvvvKPff/9dCQkJmjdv3g19Z3ZAQIDOnTunjRs36q+//srxu7ivNmDAAC1fvlwrVqzQgAEDbO0hISFKTk7W4sWLdeDAAc2YMUMrVqy45lht2rTRV199pa+++kp79uzRoEGDdObMGdv+GjVqqGfPnurTp4+WL1+ugwcPKi4uTm+88Ya+/vrrPJ8jAKD4IHQDAFCIBQYGavv27YqIiNCoUaNUr149tWvXThs3btTs2bMl/d9XeJUtW1atWrVS27ZtFRQUpCVLltjGad++vVavXq3169frjjvu0J133qm3335b1apVu6n6SpUqpW+++UYVKlTQfffdp/r16+v111/Pdmn1FU888YQ++ugjRUdHq379+goPD1d0dLTt6eJ50aJFCz399NPq0aOHfHx8NGXKlGv2f/DBB2W1WmW1Wu0ur+/atatGjBihIUOGqGHDhvrxxx/10ksvXXOs/v37q2/fvrZfagQGBtpWua+YN2+e+vTpo1GjRqlmzZq6//77tW3bNrt77gEAtw+L8e8bkwAAAAAAQIFgpRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADDJ/wPU7EXqjNYXYQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=coefs, y=feature_names)\n",
    "plt.title('ElasticNet Coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187e397-b651-4b74-a559-1b294fc812d1",
   "metadata": {},
   "source": [
    "This plot virtualized the impact of those selected predictor variables on predicted variable salary. CRBI has the greatest positive impact around 98 and the Division_W has the most negative impact of 45. The coefficient value explained how much each variable changes gonna effect the salary amout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c92ee-0a84-4ebc-87eb-ae27553b6182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
